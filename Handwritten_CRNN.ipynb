{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNvMwQfi/jn2t95UGsZlM6R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D43_T5inpi5x","executionInfo":{"status":"ok","timestamp":1771266271846,"user_tz":-330,"elapsed":367618,"user":{"displayName":"SEELAM SULOCHANA 23BCE20032","userId":"04275657600793220018"}},"outputId":"3ca552e7-992f-4067-e958-2767533108fd"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 73ms/step - accuracy: 0.6842 - loss: 0.9260 - val_accuracy: 0.9605 - val_loss: 0.1376\n","Epoch 2/5\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 71ms/step - accuracy: 0.9606 - loss: 0.1291 - val_accuracy: 0.9687 - val_loss: 0.1062\n","Epoch 3/5\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9736 - loss: 0.0851 - val_accuracy: 0.9760 - val_loss: 0.0787\n","Epoch 4/5\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.9818 - loss: 0.0586 - val_accuracy: 0.9830 - val_loss: 0.0573\n","Epoch 5/5\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 72ms/step - accuracy: 0.9840 - loss: 0.0505 - val_accuracy: 0.9843 - val_loss: 0.0520\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9851 - loss: 0.0505\n","Test Accuracy: 0.9871000051498413\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n","Confusion Matrix:\n","[[ 972    0    1    0    1    0    2    2    2    0]\n"," [   0 1123    2    0    1    0    3    5    1    0]\n"," [   1    3 1015    0    2    0    0    5    6    0]\n"," [   0    0    2  985    0   10    0    4    6    3]\n"," [   0    0    0    0  977    0    0    0    0    5]\n"," [   0    0    0    3    1  880    1    1    2    4]\n"," [   4    1    2    0    4    3  940    0    4    0]\n"," [   2    2    6    1    1    0    0 1015    0    1]\n"," [   2    0    0    0    0    2    0    2  965    3]\n"," [   1    0    0    0    5    0    0    3    1  999]]\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99       980\n","           1       0.99      0.99      0.99      1135\n","           2       0.99      0.98      0.99      1032\n","           3       1.00      0.98      0.99      1010\n","           4       0.98      0.99      0.99       982\n","           5       0.98      0.99      0.98       892\n","           6       0.99      0.98      0.99       958\n","           7       0.98      0.99      0.98      1028\n","           8       0.98      0.99      0.98       974\n","           9       0.98      0.99      0.99      1009\n","\n","    accuracy                           0.99     10000\n","   macro avg       0.99      0.99      0.99     10000\n","weighted avg       0.99      0.99      0.99     10000\n","\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import classification_report, confusion_matrix\n","import numpy as np\n","\n","# 1. Load dataset\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# 2. Normalize\n","x_train = x_train / 255.0\n","x_test = x_test / 255.0\n","\n","# 3. Reshape for CNN\n","x_train = x_train.reshape(-1, 28, 28, 1)\n","x_test = x_test.reshape(-1, 28, 28, 1)\n","\n","# 4. One-hot encoding\n","y_train_cat = to_categorical(y_train, 10)\n","y_test_cat = to_categorical(y_test, 10)\n","\n","# 5. Build CNN + RNN Model\n","model = models.Sequential()\n","\n","# CNN Layers\n","model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n","model.add(layers.MaxPooling2D((2,2)))\n","model.add(layers.Conv2D(64, (3,3), activation='relu'))\n","model.add(layers.MaxPooling2D((2,2)))\n","\n","# Convert CNN output to sequence for LSTM\n","model.add(layers.Reshape((25, 64)))  # Adjust shape for LSTM: (timesteps, features)\n","\n","# LSTM Layer\n","model.add(layers.LSTM(64))\n","\n","# Dense Layers\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","# 6. Compile\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# 7. Train\n","model.fit(x_train, y_train_cat,\n","          epochs=5,\n","          batch_size=64,\n","          validation_split=0.2)\n","\n","# 8. Evaluate\n","test_loss, test_acc = model.evaluate(x_test, y_test_cat)\n","print(\"Test Accuracy:\", test_acc)\n","\n","# 9. Confusion Matrix & Report\n","y_pred = model.predict(x_test)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","\n","print(\"Confusion Matrix:\")\n","print(confusion_matrix(y_test, y_pred_classes))\n","\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred_classes))"]}]}